
This project is a response to Problem 1 from the spider.io test
questions.

The project consists of two pieces: the main perl script ("test1.pl"),
together with an associated module, containing various subroutines
("Test1.pm").

The script downloads the daily list of the top 1,000,000 websites
generated by Alexa.com from the link:
http://s3.amazonaws.com/alexa-static/top-1m.csv.zip

It uncompresses this, and extracts the top 100,000 sites.

It then uses the database of "bugs" maintained by the developers of
the Ghostery plugin (www.ghostery.com). This database is available at:
http://www.ghostery.com/update/all?format=json. This file is
downloaded to "bugs.js" in the local directory.

The bugs file is parsed for the list of bugs currently known to
Ghostery. For each bug, Ghostery has an information page located at a
link of the form: http://www.ghostery.com/apps/Bug_Name. These data
files contain a listing of example websites on which the bug has been
found. The script goes through the list of bugs from the Ghostery
database, and for each downloads the Ghostery information page. It
then parses the downloaded information page to extract the list of
example sites for each bug. For each bug, the examples listed by
Ghostery are then cross-referenced with the list of top 100,000
sites. The bugs which have an example appearing in the top sites list
are then printed.

The outputs of the code are two files: "top100000.txt", which simply
contains a list of the top 100,000 sites extracted from the Alexa csv
file; and "bugs_in_top_100000_websites.txt", which is a list of the
bugs about which Ghostery knows that appear on the top 100,000 sites.

The script will not overwrite existing copies of the top 1 million
sites "top-1m.csv.zip", the Ghostery bugs database ("bug.js"), or any
of the downloaded bug webpages ("Bug_Name.html"). All these files are
left behind after running the script.

Brent Walker, Feb. 2012.
